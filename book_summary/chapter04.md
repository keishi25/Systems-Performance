# Chapter 4: Observability Tools まとめ

## 4.1 Tool Coverage

- 各OSコンポーネント（CPU・メモリ・ディスク・ネットワーク等）に対応するツールをマッピングした図（Figure 4.1）が基本
- マルチツール: `perf`, `Ftrace`, `BCC`, `bpftrace`（複数領域を横断的に分析できる）

### 4.1.1 Static Performance Tools

- システムが**稼働中ではなく「静止状態」**を調べるツール群
- 設定ミスや構成の問題の発見に使う（Figure 4.2）
- 例: `uname -a`, `lscpu`, `lsblk`, `df -h`, `sysctl -a`, `ifconfig` など

### 4.1.2 Crisis Tools

- 本番障害発生時に必要なツールが**そもそも入っていない**問題への対策
- サーバーが高負荷な状態でのインストールは遅くなり、障害を長引かせる

**推奨パッケージ（Ubuntu/Debian）:**

| パッケージ | 主なツール |
|---|---|
| `procps` | `ps`, `vmstat`, `uptime`, `top` |
| `util-linux` | `dmesg`, `lsblk`, `lscpu` |
| `sysstat` | `iostat`, `mpstat`, `pidstat`, `sar` |
| `iproute2` | `ip`, `ss`, `nstat`, `tc` |
| `bcc-tools` | `opensnoop`, `execsnoop`, `runqlat`, `biosnoop` など多数 |
| `bpftrace` | `bpftrace` + 各種ツールの基本版 |

**コンテナ環境でのデバッグコンテナ:**

- 本番コンテナは差し替えではなく「並走」して観察する
- デバッグ専用の特権コンテナ（ツール全部入り）を用意し、障害時に起動する
- `--pid=container:xxx` / `--network=container:xxx` でnamespaceを共有
- Kubernetes では `kubectl debug` コマンドが同じ役割（Ephemeral Container）
- GKE Standard では利用可能。Autopilot は `--privileged` に制限あり

---

## 4.2 Tool Types

観察対象（システム全体 vs プロセス単体）× 収集方法（カウンタ vs イベント）で4象限に分類。

| | システム全体 | プロセス単体 |
|---|---|---|
| **カウンタ** | `vmstat`, `iostat`, `sar` | `ps`, `pmap` |
| **イベント** | `perf`, `bpftrace`, `tcpdump` | `strace`, `gdb` |

### 4.2.1 Fixed Counters（固定カウンタ）
- カーネルが常時維持している累積カウンタを読む
- オーバーヘッドはほぼゼロ（「無料」で使える）

### 4.2.2 Profiling（プロファイリング）
- 一定間隔（99 Hz）でスナップショットを取り、CPUを消費しているコードパスを特定
- **99 Hz の理由**: 100 Hzだとカーネルタイマーとロックステップ（同期）してしまい偏りが生じるため

### 4.2.3 Tracing（トレーシング）
- イベントの**全発生**を記録する（サンプリングではなく全件収集）
- プロファイリングよりCPU・ストレージオーバーヘッドが高い → 必要時のみ有効化

### 4.2.4 Monitoring（モニタリング）
- メトリクスを継続的に収集・保存・可視化する仕組み
- 例: Prometheus, PCP (Performance Co-Pilot), collectd

---

## 4.3 Observability Sources

### 4.3.1 /proc
- カーネル統計のファイルシステムインターフェース
- プロセスごとのディレクトリ（`/proc/<PID>/`）＋システム全体の統計ファイル

### 4.3.5 Tracepoints（トレースポイント）
- **スタティックインストルメンテーション**: カーネルのソースコードにコンパイル時に埋め込まれた計装ポイント
- 安定したAPI（バージョン間で保証）。Linuxカーネルに約1808個存在
- 配置箇所: システムコール開始・終了、スケジューライベント、ディスクI/Oなど

### 4.3.6 kprobes
- **ダイナミックインストルメンテーション**: カーネルの**任意の関数・命令**を実行時に動的に計装
- 不安定API（カーネル関数名/引数がバージョン間で変わりうる）
- トレースポイントが存在しない箇所の調査に使う
- 最小コスト: kprobe ≈ 76ns、kretprobe ≈ 212ns

### 4.3.7 uprobes
- kprobesのユーザー空間版。アプリ・ライブラリの**任意の関数**を動的に計装
- 不安定API。カーネルへのトラップが必要なため kprobes より高コスト
- 最小コスト: uprobe ≈ 1,287ns、uretprobe ≈ 1,931ns

### 4.3.8 USDT（User-level Statically-Defined Tracing）

**「ユーザー空間版のトレースポイント」**

| | カーネル空間 | ユーザー空間 |
|---|---|---|
| スタティック | tracepoints | **USDT** |
| ダイナミック | kprobes | uprobes |

- アプリ開発者がソースコードに計装ポイントを埋め込む → 安定したAPI
- 内部実装は uprobes を使用
- 対応アプリ例: OpenJDK（524プローブ）、PostgreSQL、libc

**OpenJDK の主要プローブ:**

| プローブ | タイミング |
|---|---|
| `hotspot:gc__begin` / `gc__end` | GC 開始・終了 |
| `hotspot:method__compile__begin` / `end` | JITコンパイル |
| `hotspot:class__loaded` / `unloaded` | クラスロード・アンロード |

**使い方（bpftrace）:**

```bash
# 利用可能なUSDTプローブを確認
bpftrace -l 'usdt:/usr/lib/jvm/.../libjvm.so:*'

# GCをトレース
bpftrace -e '
usdt:/usr/lib/jvm/.../libjvm.so:hotspot:gc__begin { @start = nsecs; }
usdt:/usr/lib/jvm/.../libjvm.so:hotspot:gc__end {
    printf("GC: %d ms\n", (nsecs - @start) / 1000000);
}'
```

**注意点:**
- OpenJDKはデフォルトでUSDT無効 → `--enable-dtrace-probes` 付きでビルドが必要
- JIT言語（Java, Node.js）はコンパイル時埋め込みが困難 → **Dynamic USDT** で対応
- Spring Boot は JVM の USDT プローブを間接的に利用できる

**マネージドサービス（Cloud Spanner等）の場合:**

サーバー側はブラックボックスなのでUSDT/kprobesは不可。クライアント側は **OpenTelemetry** で計装するのが標準的アプローチ。

```
Spring Boot アプリ
  └── OpenTelemetry SDK
        ├── Traces  → Cloud Trace / Jaeger
        ├── Metrics → Cloud Monitoring / Prometheus
        └── Logs    → Cloud Logging / Loki
```

### 4.3.9 Hardware Counters（PMCs）
- CPUハードウェアに内蔵されたカウンタ
- ソフトウェアでは観測できないCPUレベルの挙動を計測（キャッシュミス、IPC、分岐予測ミスなど）
- オーバーヘッドほぼゼロ（ハードウェアで完結）
- クラウド環境では利用に制限がある場合あり
- Linuxでは `perf_event_open(2)` 経由でアクセス

---

## 4.6 Observing Observability

- ツールや統計値自体にもバグがある可能性を忘れずに
- man ページが常に正しいとは限らない
- メトリクスが不完全・欠落している場合もある → 健全な懐疑心を持つ

---

## 4.7 練習問題 Q&A

**Q1. スタティックパフォーマンスツールをいくつか挙げよ。**

> システムが「静止状態」にある属性を調べるツール。
> 例: `uname -a`（カーネルバージョン）、`lscpu`（CPU情報）、`lsblk`（ブロックデバイス構成）、`df -h`（ファイルシステム使用量）、`ifconfig`/`ip`（ネットワーク設定）、`sysctl -a`（カーネルパラメータ）など。
> 設定ミスや構成の問題を発見するために使う。

---

**Q2. プロファイリングとは何か？**

> ターゲットの動作をサンプリング（スナップショット）で特徴づける手法。
> タイマーベースのサンプリングで、CPUの命令ポインタやスタックトレースを一定間隔（例: 99 Hz）で収集し、CPU時間を消費しているコードパスを特定する。

---

**Q3. プロファイラが 100 Hz ではなく 99 Hz を使う理由は？**

> 100 Hz のような切りの良い値では、カーネルのタイマー割り込みなど周期100 Hzで動く処理と「ロックステップ（同期）」してしまい、特定のイベントを過剰にカウントしたり見逃したりするリスクがある。
> 99 Hz のようなずれた値を使うことで偏りを避け、ランダムなサンプリングに近づけることができる。

---

**Q4. トレーシングとは何か？**

> イベントの**全発生**を計装し、詳細をストレージに記録したりサマリを生成したりする手法。
> プロファイリングとは異なり「全件収集」が目的。CPU・ストレージオーバーヘッドが高くなる場合があるため、通常は必要なときのみ有効にする。

---

**Q5. スタティックインストルメンテーションとは何か？**

> カーネルのソースコードに**コンパイル時にあらかじめ**埋め込まれた計装ポイント（フック）のこと。
> Linuxでは**トレースポイント（tracepoints）** がこれに相当する。システムコールの開始・終了、スケジューライベント、ディスクI/Oなどに配置されており、安定したAPIを提供するが数に限りがある。

---

**Q6. ダイナミックインストルメンテーションが重要な理由を説明せよ。**

> トレースポイントはカーネル内の限られた箇所にしかない。
> ダイナミックインストルメンテーション（**kprobes** / **uprobes**）は、カーネルやユーザー空間の**任意の関数・命令**を実行時に動的に計装できる。
> トレースポイントが存在しない箇所の調査が可能になり、カーネルの再コンパイルや再起動も不要。

---

**Q7. トレースポイントと kprobes の違いは何か？**

| | トレースポイント | kprobes |
|---|---|---|
| 種類 | スタティック（コンパイル時埋め込み） | ダイナミック（実行時に動的に設定） |
| API安定性 | 安定（バージョン間で保証） | 不安定（カーネル関数名/引数が変わりうる） |
| カバレッジ | 限られた計装ポイントのみ | カーネルの任意の関数・命令 |
| 用途 | 安定したツール開発に向く | トレースポイントがない箇所の調査に使う |

---

**Q8. 以下の操作のCPUオーバーヘッドを予測せよ（低/中/高）。**

| 操作 | オーバーヘッド | 理由 |
|---|---|---|
| ディスクIOPSカウンタ（`iostat`で見るもの） | **低** | カーネルが常時維持しているカウンタを読むだけ |
| トレースポイント/kprobesでのディスクI/Oイベントトレース | **中** | I/Oごとにトレーサが動くが、I/O頻度は一般的に低め |
| コンテキストスイッチのイベントトレース | **高** | コンテキストスイッチは非常に頻繁（数千/秒）に発生する |
| `execve(2)` のイベントトレース | **低** | プロセス生成は比較的まれなイベント |
| uprobesによる `libc malloc()` のトレース | **高** | uprobe自体のコストが高い（≈1287ns/call）＋mallocは非常に高頻度 |

---

**Q9. PMCがパフォーマンス分析において価値がある理由を説明せよ。**

> PMC（Performance Monitoring Counters）はCPUハードウェアに内蔵されたカウンタで、ソフトウェアだけでは観測できないCPUレベルの挙動を計測できる。
> キャッシュミス、命令数、サイクル数、分岐予測ミスなどを計測でき、IPC（Instructions Per Cycle）の算出も可能。
> ハードウェアで完結するためオーバーヘッドが非常に小さい。クラウド環境では利用に制限がある場合がある。

---

**Q10. あるオブザーバビリティツールが何の計装ソースを使っているか、どうやって調べるか？**

> `strace` コマンドでツールを実行し、システムコールを観察する方法が有効。
> `strace ツール名` を実行すると、そのツールがどのファイル（`/proc`、`/sys`、tracefs等）やシステムコール（`perf_event_open` など）を呼んでいるかが分かる。
> ツールのソースコード・ドキュメント・man ページを読む方法もある。
